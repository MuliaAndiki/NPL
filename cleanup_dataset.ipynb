{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cf7eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cbb8a7",
   "metadata": {},
   "source": [
    "`Configuration Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = 'dataset'\n",
    "cleaned_data_dir = 'datasets_cleaned'\n",
    "file_to_clean_name = 'etd_ugm.csv'\n",
    "\n",
    "input_filepath = os.path.join(raw_data_dir, file_to_clean_name)\n",
    "output_filepath = os.path.join(cleaned_data_dir, file_to_clean_name)\n",
    "\n",
    "print(\"Konfigurasi Selesai:\")\n",
    "print(f\"  File Input Target : {input_filepath}\")\n",
    "print(f\"  File Output       : {output_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040cc28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_quote_csv(input_filepath, output_filepath):\n",
    "    os.makedirs(os.path.dirname(output_filepath), exist_ok=True)\n",
    "    \n",
    "    df = pd.read_csv(input_filepath)\n",
    "    \n",
    "    df = df.replace(\"‚Äì\", \"-\", regex=True)\n",
    "    \n",
    "    if 'judul' in df.columns:\n",
    "        df['judul'] = df['judul'].apply(\n",
    "            lambda x: f'\"{x}\"' if not (str(x).startswith('\"') and str(x).endswith('\"')) else x\n",
    "        )\n",
    "    \n",
    "    df.to_csv(output_filepath, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(\"\\nProses pembersihan selesai!\")\n",
    "    print(f\"File bersih disimpan di: {output_filepath}\")\n",
    "\n",
    "input_filepath = os.path.join(raw_data_dir, file_to_clean_name)\n",
    "output_filepath = os.path.join(cleaned_data_dir, file_to_clean_name)\n",
    "\n",
    "print(\"Konfigurasi Selesai:\")\n",
    "print(f\"  File Input Target : {input_filepath}\")\n",
    "print(f\"  File Output       : {output_filepath}\")\n",
    "\n",
    "clean_and_quote_csv(input_filepath, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_quote_csv(input_filepath, output_filepath):\n",
    "    os.makedirs(os.path.dirname(output_filepath), exist_ok=True)\n",
    "    \n",
    "    df = pd.read_csv(input_filepath)\n",
    "    \n",
    "    df = df.replace(\"‚Äì\", \"-\", regex=True)\n",
    "    \n",
    "    if 'judul' in df.columns:\n",
    "        df['judul'] = df['judul'].apply(\n",
    "            lambda x: f'\"{x}\"' if not (str(x).startswith('\"') and str(x).endswith('\"')) else x\n",
    "        )\n",
    "    \n",
    "    df.to_csv(output_filepath, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(\"\\nProses pembersihan selesai!\")\n",
    "    print(f\"File bersih disimpan di: {output_filepath}\")\n",
    "\n",
    "# Konfigurasi path\n",
    "raw_data_dir = 'dataset'\n",
    "cleaned_data_dir = 'datasets_cleaned'\n",
    "file_to_clean_name = 'etd_usk.csv'\n",
    "\n",
    "input_filepath = os.path.join(raw_data_dir, file_to_clean_name)\n",
    "output_filepath = os.path.join(cleaned_data_dir, file_to_clean_name)\n",
    "\n",
    "print(\"Konfigurasi Selesai:\")\n",
    "print(f\"  File Input Target : {input_filepath}\")\n",
    "print(f\"  File Output       : {output_filepath}\")\n",
    "\n",
    "# Jalankan proses pembersihan\n",
    "clean_and_quote_csv(input_filepath, output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cde340",
   "metadata": {},
   "source": [
    "`Formating untuk dataset khusus etd_ugm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e81cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_all_formats(input_filepath, output_filepath):\n",
    "    os.makedirs(os.path.dirname(output_filepath), exist_ok=True)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with open(input_filepath, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    entries = re.split(r'\\n(?=[^\",\\n]+,\")', content)\n",
    "    \n",
    "    if len(entries) <= 1:\n",
    "        entries = re.split(r'\\n\"(?=[^\"]+\",\"[^\"])', content)\n",
    "    \n",
    "    for entry in entries:\n",
    "        entry = entry.strip()\n",
    "        if not entry or 'judul' in entry.lower():\n",
    "            continue\n",
    "        \n",
    "        judul, konten = parse_entry(entry)\n",
    "        \n",
    "        if judul and konten:\n",
    "            judul = clean_text(judul)\n",
    "            konten = clean_text(konten)\n",
    "            \n",
    "            data.append({'judul': judul, 'konten': konten})\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    df.to_csv(output_filepath, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"‚úÖ Formatting selesai!\")\n",
    "    print(f\"   Data diproses: {len(data)} baris\")\n",
    "    print(f\"   File disimpan: {output_filepath}\")\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        print(f\"\\nüìã Sample hasil:\")\n",
    "        print(\"=\" * 80)\n",
    "        for i in range(min(3, len(df))):\n",
    "            print(f\"Data {i+1}:\")\n",
    "            print(f\"  Judul: {df['judul'].iloc[i][:80]}...\")\n",
    "            print(f\"  Konten: {df['konten'].iloc[i][:80]}...\")\n",
    "            print()\n",
    "\n",
    "def parse_entry(entry):\n",
    "    entry = entry.strip()\n",
    "    \n",
    "    if re.match(r'^[^\"]+,\"[^\"]+', entry):\n",
    "        first_quote = entry.find('\"')\n",
    "        judul = entry[:first_quote-1].strip() if first_quote > 0 else \"\"\n",
    "        konten = entry[first_quote:].strip()\n",
    "        \n",
    "        if konten.startswith('\"') and konten.endswith('\"'):\n",
    "            konten = konten[1:-1]\n",
    "        elif konten.startswith('\"'):\n",
    "            konten = konten[1:]\n",
    "        elif konten.endswith('\"'):\n",
    "            konten = konten[:-1]\n",
    "            \n",
    "        return judul, konten\n",
    "\n",
    "    elif re.match(r'^\"[^\"]+\",\"[^\"]+', entry):\n",
    "        parts = entry.split('\",\"', 1)\n",
    "        if len(parts) == 2:\n",
    "            judul = parts[0][1:].strip() if parts[0].startswith('\"') else parts[0].strip()\n",
    "            konten = parts[1][:-1].strip() if parts[1].endswith('\"') else parts[1].strip()\n",
    "            return judul, konten\n",
    "    \n",
    "    elif entry.startswith('\"\"\"') and entry.endswith('\"\"\"'):\n",
    "        entry = entry[3:-3] \n",
    "        return parse_entry(entry)  \n",
    "    \n",
    "   \n",
    "    elif ',\"\"\"' in entry and entry.endswith('\"\"\"'):\n",
    "        parts = entry.split(',\"\"\"', 1)\n",
    "        if len(parts) == 2:\n",
    "            judul = parts[0].strip()\n",
    "            konten = parts[1][:-3].strip() \n",
    "            return judul, konten\n",
    "    \n",
    "   \n",
    "    elif ',' in entry:\n",
    "        first_comma = entry.find(',')\n",
    "        judul = entry[:first_comma].strip()\n",
    "        konten = entry[first_comma+1:].strip()\n",
    "        \n",
    "       \n",
    "        judul = judul.strip('\"')\n",
    "        konten = konten.strip('\"')\n",
    "        \n",
    "        return judul, konten\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "   \n",
    "    text = re.sub(r'\"+', '\"', text)\n",
    "    \n",
    "   \n",
    "    text = text.strip()\n",
    "    while text.startswith('\"') and text.endswith('\"'):\n",
    "        text = text[1:-1].strip()\n",
    "    \n",
    "   \n",
    "    text = text.replace(\"‚Äì\", \"-\")\n",
    "    text = text.replace(\"‚Äù\", '\"')\n",
    "    text = text.replace(\"‚Äú\", '\"')\n",
    "    \n",
    "   \n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def process_complex_file(input_filepath, output_filepath):\n",
    "    os.makedirs(os.path.dirname(output_filepath), exist_ok=True)\n",
    "    \n",
    "    data = []\n",
    "    current_entry = []\n",
    "    \n",
    "    with open(input_filepath, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if not line or 'judul' in line.lower():\n",
    "                continue\n",
    "            \n",
    "           \n",
    "            if re.match(r'^[^\",]+,\"[^\"]+', line) and current_entry:\n",
    "                process_current_entry(current_entry, data)\n",
    "                current_entry = []\n",
    "            \n",
    "            current_entry.append(line)\n",
    "        \n",
    "       \n",
    "        if current_entry:\n",
    "            process_current_entry(current_entry, data)\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "   \n",
    "    df.to_csv(output_filepath, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"‚úÖ Complex formatting selesai!\")\n",
    "    print(f\"   Data diproses: {len(data)} baris\")\n",
    "    print(f\"   File disimpan: {output_filepath}\")\n",
    "\n",
    "def process_current_entry(entry_lines, data):\n",
    "  \n",
    "    full_entry = ' '.join(entry_lines)\n",
    "    judul, konten = parse_entry(full_entry)\n",
    "    \n",
    "    if judul and konten:\n",
    "        judul = clean_text(judul)\n",
    "        konten = clean_text(konten)\n",
    "        data.append({'judul': judul, 'konten': konten})\n",
    "\n",
    "\n",
    "input_filepath = os.path.join('dataset', 'etd_ugm.csv')\n",
    "output_filepath = os.path.join('datasets_cleaned', 'etd_ugm.csv')\n",
    "\n",
    "print(\"Memulai proses formatting...\")\n",
    "print(f\"  Input : {input_filepath}\")\n",
    "print(f\"  Output: {output_filepath}\")\n",
    "try:\n",
    "    fix_all_formats(input_filepath, output_filepath)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Method 1 failed: {e}\")\n",
    "    print(\"Trying complex method...\")\n",
    "    try:\n",
    "        process_complex_file(input_filepath, output_filepath)\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå All methods failed: {e2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5f0cc-95e4-4c8e-8dd6-86e7dd972516",
   "metadata": {},
   "source": [
    "## Cleanup Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f368ece",
   "metadata": {},
   "source": [
    "`Mojok-Dataset` - `Fix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2274ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_excessive_quotes(text):\n",
    "  \n",
    "    if not text:\n",
    "        return text\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    if text.count('\"') >= 4:\n",
    "        print(f\"DEBUG: Banyak kutip ditemukan: {text[:100]}...\")\n",
    "    \n",
    "  \n",
    "    while text.startswith('\"\"\"'):\n",
    "        text = text[3:]\n",
    "    while text.startswith('\"\"'):\n",
    "        text = text[2:]\n",
    "    if text.startswith('\"'):\n",
    "        text = text[1:]\n",
    "    \n",
    "    while text.endswith('\"\"\"'):\n",
    "        text = text[:-3]\n",
    "    while text.endswith('\"\"'):\n",
    "        text = text[:-2]\n",
    "    if text.endswith('\"'):\n",
    "        text = text[:-1]\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def remove_source_prefix(text):\n",
    "   \n",
    "    if not text:\n",
    "        return text\n",
    "    \n",
    "  \n",
    "    patterns = [\n",
    "        r'^\"\\s*KOMPAS\\.com\\s*[‚Äì\\-]\\s*',\n",
    "        r'^KOMPAS\\.com\\s*[‚Äì\\-]\\s*',\n",
    "        r'^\"\\s*KOMPAS\\.com\\s*',\n",
    "        r'^KOMPAS\\.com\\s*',\n",
    "        r'^\\(\\s*KOMPAS\\.com\\s*\\)\\s*',\n",
    "        r'^\\[\\s*KOMPAS\\.com\\s*\\]\\s*'\n",
    "    ]\n",
    "    \n",
    "    cleaned_text = text.strip()\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.match(pattern, cleaned_text, re.IGNORECASE):\n",
    "            cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.IGNORECASE)\n",
    "            break\n",
    "    \n",
    "   \n",
    "    cleaned_text = cleaned_text.replace('\"\"', '\"')\n",
    "    \n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def parse_csv_line_robust(line):\n",
    "    line = line.strip()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        reader = csv.reader([line], quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "        row = next(reader)\n",
    "        if len(row) == 2:\n",
    "            return [clean_excessive_quotes(row[0]), clean_excessive_quotes(row[1])]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "   \n",
    "    match = re.match(r'^\"([^\"]*)\"\\s*,\\s*\"([^\"]*)\"$', line)\n",
    "    if match:\n",
    "        judul = clean_excessive_quotes(match.group(1))\n",
    "        konten = clean_excessive_quotes(match.group(2))\n",
    "        return [judul, konten]\n",
    "    \n",
    "   \n",
    "    if line.count('\"') >= 4:\n",
    "       \n",
    "        parts = re.split(r',\\s*\"', line, 1)\n",
    "        if len(parts) == 2:\n",
    "            judul = clean_excessive_quotes(parts[0])\n",
    "            konten = '\"' + parts[1]  \n",
    "            konten = clean_excessive_quotes(konten)\n",
    "            return [judul, konten]\n",
    "    \n",
    "    \n",
    "    if ',' in line:\n",
    "        first_comma = line.find(',')\n",
    "        judul = line[:first_comma].strip()\n",
    "        konten = line[first_comma+1:].strip()\n",
    "        \n",
    "        judul = clean_excessive_quotes(judul)\n",
    "        konten = clean_excessive_quotes(konten)\n",
    "        \n",
    "        return [judul, konten]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def ensure_proper_quotes(judul, konten):\n",
    "    \n",
    "    judul = clean_excessive_quotes(judul)\n",
    "    konten = clean_excessive_quotes(konten)\n",
    "    \n",
    "    konten = remove_source_prefix(konten)\n",
    "    \n",
    "    judul = judul.strip('\"')\n",
    "    konten = konten.strip('\"')\n",
    "    \n",
    "    return judul, konten\n",
    "\n",
    "def clean_and_split_csv(input_path, output_path):\n",
    "    print(f\"-> Memulai pembersihan untuk: {os.path.basename(input_path)}\")\n",
    "\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    failed_lines = []\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    with open(input_path, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "         open(output_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "\n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)  \n",
    "        writer.writerow(['judul', 'konten'])\n",
    "\n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            line = line.strip()\n",
    "            \n",
    "           \n",
    "            if not line or line.lower().replace('\"', '') in ['judul,konten', 'title,content']:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            if line.count('\"') > 4:\n",
    "                print(f\"DEBUG Line {line_num}: {line[:100]}...\")\n",
    "\n",
    "            \n",
    "            parsed = parse_csv_line_robust(line)\n",
    "            if parsed and len(parsed) == 2:\n",
    "                judul, konten = parsed\n",
    "                judul, konten = ensure_proper_quotes(judul, konten)\n",
    "                \n",
    "                writer.writerow([judul, konten])\n",
    "                success_count += 1\n",
    "                continue\n",
    "\n",
    "            \n",
    "            fail_count += 1\n",
    "            failed_lines.append((line_num, line))\n",
    "\n",
    "    print(f\"-> ‚úÖ Selesai. Berhasil: {success_count} baris, Gagal: {fail_count} baris.\")\n",
    "    print(f\"   Hasil disimpan di: {output_path}\")\n",
    "    \n",
    "    if failed_lines:\n",
    "        print(f\"\\n‚ùå Baris yang gagal (total {len(failed_lines)} baris):\")\n",
    "        for i, (line_num, failed_line) in enumerate(failed_lines[:5]):\n",
    "            print(f\"   Baris {line_num}: {failed_line[:100]}...\")\n",
    "\n",
    "def validate_csv_format(file_path):\n",
    "   \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"\\n‚úÖ File berhasil dibaca oleh pandas!\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"   Kolom: {list(df.columns)}\")\n",
    "        print(f\"\\nüìä Sample data (3 baris pertama):\")\n",
    "        print(\"=\" * 100)\n",
    "        for i in range(min(3, len(df))):\n",
    "            print(f\"Baris {i+1}:\")\n",
    "            print(f\"  JUDUL:  {df['judul'].iloc[i]}\")\n",
    "            print(f\"  KONTEN: {df['konten'].iloc[i][:100]}...\")\n",
    "            print(\"-\" * 100)\n",
    "        \n",
    "       \n",
    "        print(f\"\\nüîç Format file sebenarnya:\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i < 4:  \n",
    "                    print(f\"Line {i}: {repr(line.strip())}\")\n",
    "                else:\n",
    "                    break\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR saat membaca file dengan pandas: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_test_file(input_path, output_test_path, num_lines=12):\n",
    "    print(f\"\\nüîß Membuat file test ({num_lines} baris pertama)...\")\n",
    "    \n",
    "    success_count = 0\n",
    "    \n",
    "    with open(input_path, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "         open(output_test_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        \n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)\n",
    "        writer.writerow(['judul', 'konten'])\n",
    "        \n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            line = line.strip()\n",
    "            \n",
    "            if not line or line.lower().replace('\"', '') in ['judul,konten', 'title,content']:\n",
    "                continue\n",
    "            \n",
    "            if success_count >= num_lines:\n",
    "                break\n",
    "            \n",
    "           \n",
    "            print(f\"\\n--- Baris {line_num} (Original) ---\")\n",
    "            print(f\"Raw: {repr(line)}\")\n",
    "            print(f\"Quote count: {line.count(chr(34))}\") \n",
    "            \n",
    "            \n",
    "            parsed = parse_csv_line_robust(line)\n",
    "            if parsed and len(parsed) == 2:\n",
    "                judul, konten = parsed\n",
    "                judul, konten = ensure_proper_quotes(judul, konten)\n",
    "                \n",
    "                print(f\"Judul (cleaned): {repr(judul)}\")\n",
    "                print(f\"Konten (cleaned): {repr(konten[:50])}...\")\n",
    "                \n",
    "                writer.writerow([judul, konten])\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"‚ùå Gagal parsing baris {line_num}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_filepath = os.path.join('datasets_cleaned', 'mojok.csv')\n",
    "    output_test_path = os.path.join('cleaned', 'mojok_cleaned.csv')\n",
    "    \n",
    "    if not os.path.exists(input_filepath):\n",
    "        print(f\"‚ùå File input tidak ditemukan: {input_filepath}\")\n",
    "        print(\"   Pastikan file datasets_cleaned/mojok.csv ada\")\n",
    "    else:\n",
    "        create_test_file(input_filepath, output_test_path, 9454)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VALIDASI FILE TEST:\")\n",
    "        print(\"=\"*80)\n",
    "        validate_csv_format(output_test_path)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VALIDASI FILE LENGKAP:\")\n",
    "        print(\"=\"*80)\n",
    "        validate_csv_format(output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bd14ad",
   "metadata": {},
   "source": [
    "`Kompas-Dataset` - `Fix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_excessive_quotes(text):\n",
    "    if not text:\n",
    "        return text\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    if text.count('\"') >= 4:\n",
    "        print(f\"DEBUG: Banyak kutip ditemukan: {text[:100]}...\")\n",
    "    \n",
    "  \n",
    "    while text.startswith('\"\"\"'):\n",
    "        text = text[3:]\n",
    "    while text.startswith('\"\"'):\n",
    "        text = text[2:]\n",
    "    if text.startswith('\"'):\n",
    "        text = text[1:]\n",
    "    \n",
    " \n",
    "    while text.endswith('\"\"\"'):\n",
    "        text = text[:-3]\n",
    "    while text.endswith('\"\"'):\n",
    "        text = text[:-2]\n",
    "    if text.endswith('\"'):\n",
    "        text = text[:-1]\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def remove_source_prefix(text):\n",
    "   \n",
    "    if not text:\n",
    "        return text\n",
    "    \n",
    "    \n",
    "    patterns = [\n",
    "        r'^\"\\s*KOMPAS\\.com\\s*[‚Äì\\-]\\s*',\n",
    "        r'^KOMPAS\\.com\\s*[‚Äì\\-]\\s*',\n",
    "        r'^\"\\s*KOMPAS\\.com\\s*',\n",
    "        r'^KOMPAS\\.com\\s*',\n",
    "        r'^\\(\\s*KOMPAS\\.com\\s*\\)\\s*',\n",
    "        r'^\\[\\s*KOMPAS\\.com\\s*\\]\\s*'\n",
    "    ]\n",
    "    \n",
    "    cleaned_text = text.strip()\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.match(pattern, cleaned_text, re.IGNORECASE):\n",
    "            cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.IGNORECASE)\n",
    "            break\n",
    "    \n",
    "   \n",
    "    cleaned_text = cleaned_text.replace('\"\"', '\"')\n",
    "    \n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def parse_csv_line_robust(line):\n",
    "   \n",
    "    line = line.strip()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        reader = csv.reader([line], quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "        row = next(reader)\n",
    "        if len(row) == 2:\n",
    "            return [clean_excessive_quotes(row[0]), clean_excessive_quotes(row[1])]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "  \n",
    "    match = re.match(r'^\"([^\"]*)\"\\s*,\\s*\"([^\"]*)\"$', line)\n",
    "    if match:\n",
    "        judul = clean_excessive_quotes(match.group(1))\n",
    "        konten = clean_excessive_quotes(match.group(2))\n",
    "        return [judul, konten]\n",
    "    \n",
    "    \n",
    "    if line.count('\"') >= 4:\n",
    "       \n",
    "        parts = re.split(r',\\s*\"', line, 1)\n",
    "        if len(parts) == 2:\n",
    "            judul = clean_excessive_quotes(parts[0])\n",
    "            konten = '\"' + parts[1] \n",
    "            konten = clean_excessive_quotes(konten)\n",
    "            return [judul, konten]\n",
    "    \n",
    "   \n",
    "    if ',' in line:\n",
    "        first_comma = line.find(',')\n",
    "        judul = line[:first_comma].strip()\n",
    "        konten = line[first_comma+1:].strip()\n",
    "        \n",
    "        judul = clean_excessive_quotes(judul)\n",
    "        konten = clean_excessive_quotes(konten)\n",
    "        \n",
    "        return [judul, konten]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def ensure_proper_quotes(judul, konten):\n",
    "   \n",
    "   \n",
    "    judul = clean_excessive_quotes(judul)\n",
    "    konten = clean_excessive_quotes(konten)\n",
    "    \n",
    "  \n",
    "    konten = remove_source_prefix(konten)\n",
    "    \n",
    "    \n",
    "    judul = judul.strip('\"')\n",
    "    konten = konten.strip('\"')\n",
    "    \n",
    "    return judul, konten\n",
    "\n",
    "def clean_and_split_csv(input_path, output_path):\n",
    "    print(f\"-> Memulai pembersihan untuk: {os.path.basename(input_path)}\")\n",
    "\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    failed_lines = []\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    with open(input_path, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "         open(output_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "\n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)  \n",
    "        writer.writerow(['judul', 'konten'])\n",
    "\n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            line = line.strip()\n",
    "            \n",
    "           \n",
    "            if not line or line.lower().replace('\"', '') in ['judul,konten', 'title,content']:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            if line.count('\"') > 4:\n",
    "                print(f\"DEBUG Line {line_num}: {line[:100]}...\")\n",
    "\n",
    "           \n",
    "            parsed = parse_csv_line_robust(line)\n",
    "            if parsed and len(parsed) == 2:\n",
    "                judul, konten = parsed\n",
    "                judul, konten = ensure_proper_quotes(judul, konten)\n",
    "                \n",
    "                writer.writerow([judul, konten])\n",
    "                success_count += 1\n",
    "                continue\n",
    "\n",
    "           \n",
    "            fail_count += 1\n",
    "            failed_lines.append((line_num, line))\n",
    "\n",
    "    print(f\"-> ‚úÖ Selesai. Berhasil: {success_count} baris, Gagal: {fail_count} baris.\")\n",
    "    print(f\"   Hasil disimpan di: {output_path}\")\n",
    "    \n",
    "    if failed_lines:\n",
    "        print(f\"\\n‚ùå Baris yang gagal (total {len(failed_lines)} baris):\")\n",
    "        for i, (line_num, failed_line) in enumerate(failed_lines[:5]):\n",
    "            print(f\"   Baris {line_num}: {failed_line[:100]}...\")\n",
    "\n",
    "def validate_csv_format(file_path):\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"\\n‚úÖ File berhasil dibaca oleh pandas!\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"   Kolom: {list(df.columns)}\")\n",
    "        print(f\"\\nüìä Sample data (3 baris pertama):\")\n",
    "        print(\"=\" * 100)\n",
    "        for i in range(min(3, len(df))):\n",
    "            print(f\"Baris {i+1}:\")\n",
    "            print(f\"  JUDUL:  {df['judul'].iloc[i]}\")\n",
    "            print(f\"  KONTEN: {df['konten'].iloc[i][:100]}...\")\n",
    "            print(\"-\" * 100)\n",
    "        \n",
    "       \n",
    "        print(f\"\\nüîç Format file sebenarnya:\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i < 4:  \n",
    "                    print(f\"Line {i}: {repr(line.strip())}\")\n",
    "                else:\n",
    "                    break\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR saat membaca file dengan pandas: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_test_file(input_path, output_test_path, num_lines=12):\n",
    "    print(f\"\\nüîß Membuat file test ({num_lines} baris pertama)...\")\n",
    "    \n",
    "    success_count = 0\n",
    "    \n",
    "    with open(input_path, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "         open(output_test_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        \n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)\n",
    "        writer.writerow(['judul', 'konten'])\n",
    "        \n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            line = line.strip()\n",
    "            \n",
    "            if not line or line.lower().replace('\"', '') in ['judul,konten', 'title,content']:\n",
    "                continue\n",
    "            \n",
    "            if success_count >= num_lines:\n",
    "                break\n",
    "            \n",
    "            \n",
    "            print(f\"\\n--- Baris {line_num} (Original) ---\")\n",
    "            print(f\"Raw: {repr(line)}\")\n",
    "            print(f\"Quote count: {line.count(chr(34))}\")  \n",
    "            \n",
    "            \n",
    "            parsed = parse_csv_line_robust(line)\n",
    "            if parsed and len(parsed) == 2:\n",
    "                judul, konten = parsed\n",
    "                judul, konten = ensure_proper_quotes(judul, konten)\n",
    "                \n",
    "                print(f\"Judul (cleaned): {repr(judul)}\")\n",
    "                print(f\"Konten (cleaned): {repr(konten[:50])}...\")\n",
    "                \n",
    "                writer.writerow([judul, konten])\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"‚ùå Gagal parsing baris {line_num}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_filepath = os.path.join('datasets_cleaned', 'kompas.csv')\n",
    "    output_test_path = os.path.join('cleaned', 'kompas_cleaned.csv')\n",
    "    \n",
    "    if not os.path.exists(input_filepath):\n",
    "        print(f\"‚ùå File input tidak ditemukan: {input_filepath}\")\n",
    "        print(\"   Pastikan file datasets_cleaned/kompas.csv ada\")\n",
    "    else:\n",
    "        create_test_file(input_filepath, output_test_path, 9099)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VALIDASI FILE TEST:\")\n",
    "        print(\"=\"*80)\n",
    "        validate_csv_format(output_test_path)\n",
    "        \n",
    "        # Validasi file lengkap\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VALIDASI FILE LENGKAP:\")\n",
    "        print(\"=\"*80)\n",
    "        validate_csv_format(output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a58d9",
   "metadata": {},
   "source": [
    "`Tempo Dataset` - `Fix`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75626258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_excessive_quotes(text):\n",
    "    if not text:\n",
    "        return text\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    if text.count('\"') >= 4:\n",
    "        print(f\"DEBUG: Banyak kutip ditemukan: {text[:100]}...\")\n",
    "    \n",
    "   \n",
    "    while text.startswith('\"\"\"'):\n",
    "        text = text[3:]\n",
    "    while text.startswith('\"\"'):\n",
    "        text = text[2:]\n",
    "    if text.startswith('\"'):\n",
    "        text = text[1:]\n",
    "    \n",
    "    while text.endswith('\"\"\"'):\n",
    "        text = text[:-3]\n",
    "    while text.endswith('\"\"'):\n",
    "        text = text[:-2]\n",
    "    if text.endswith('\"'):\n",
    "        text = text[:-1]\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def remove_source_prefix(text):\n",
    "    if not text:\n",
    "        return text\n",
    "    \n",
    "    patterns = [\n",
    "        r'^\"\\s*KOMPAS\\.com\\s*[‚Äì\\-]\\s*',\n",
    "        r'^KOMPAS\\.com\\s*[‚Äì\\-]\\s*',\n",
    "        r'^\"\\s*KOMPAS\\.com\\s*',\n",
    "        r'^KOMPAS\\.com\\s*',\n",
    "        r'^\\(\\s*KOMPAS\\.com\\s*\\)\\s*',\n",
    "        r'^\\[\\s*KOMPAS\\.com\\s*\\]\\s*'\n",
    "    ]\n",
    "    \n",
    "    cleaned_text = text.strip()\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.match(pattern, cleaned_text, re.IGNORECASE):\n",
    "            cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.IGNORECASE)\n",
    "            break\n",
    "    \n",
    "   \n",
    "    cleaned_text = cleaned_text.replace('\"\"', '\"')\n",
    "    \n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def parse_csv_line_robust(line):\n",
    "   \n",
    "    line = line.strip()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        reader = csv.reader([line], quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "        row = next(reader)\n",
    "        if len(row) == 2:\n",
    "            return [clean_excessive_quotes(row[0]), clean_excessive_quotes(row[1])]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "   \n",
    "    match = re.match(r'^\"([^\"]*)\"\\s*,\\s*\"([^\"]*)\"$', line)\n",
    "    if match:\n",
    "        judul = clean_excessive_quotes(match.group(1))\n",
    "        konten = clean_excessive_quotes(match.group(2))\n",
    "        return [judul, konten]\n",
    "    \n",
    "   \n",
    "    if line.count('\"') >= 4:\n",
    "        \n",
    "        parts = re.split(r',\\s*\"', line, 1)\n",
    "        if len(parts) == 2:\n",
    "            judul = clean_excessive_quotes(parts[0])\n",
    "            konten = '\"' + parts[1]  \n",
    "            konten = clean_excessive_quotes(konten)\n",
    "            return [judul, konten]\n",
    "    \n",
    "    \n",
    "    if ',' in line:\n",
    "        first_comma = line.find(',')\n",
    "        judul = line[:first_comma].strip()\n",
    "        konten = line[first_comma+1:].strip()\n",
    "        \n",
    "        judul = clean_excessive_quotes(judul)\n",
    "        konten = clean_excessive_quotes(konten)\n",
    "        \n",
    "        return [judul, konten]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def ensure_proper_quotes(judul, konten):\n",
    "   \n",
    "   \n",
    "    judul = clean_excessive_quotes(judul)\n",
    "    konten = clean_excessive_quotes(konten)\n",
    "    \n",
    "   \n",
    "    konten = remove_source_prefix(konten)\n",
    "    \n",
    "   \n",
    "    judul = judul.strip('\"')\n",
    "    konten = konten.strip('\"')\n",
    "    \n",
    "    return judul, konten\n",
    "\n",
    "def clean_and_split_csv(input_path, output_path):\n",
    "    print(f\"-> Memulai pembersihan untuk: {os.path.basename(input_path)}\")\n",
    "\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    failed_lines = []\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    with open(input_path, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "         open(output_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "\n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_ALL) \n",
    "        writer.writerow(['judul', 'konten'])\n",
    "\n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            line = line.strip()\n",
    "            \n",
    "           \n",
    "            if not line or line.lower().replace('\"', '') in ['judul,konten', 'title,content']:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            if line.count('\"') > 4:\n",
    "                print(f\"DEBUG Line {line_num}: {line[:100]}...\")\n",
    "\n",
    "           \n",
    "            parsed = parse_csv_line_robust(line)\n",
    "            if parsed and len(parsed) == 2:\n",
    "                judul, konten = parsed\n",
    "                judul, konten = ensure_proper_quotes(judul, konten)\n",
    "                \n",
    "                writer.writerow([judul, konten])\n",
    "                success_count += 1\n",
    "                continue\n",
    "\n",
    "           \n",
    "            fail_count += 1\n",
    "            failed_lines.append((line_num, line))\n",
    "\n",
    "    print(f\"-> ‚úÖ Selesai. Berhasil: {success_count} baris, Gagal: {fail_count} baris.\")\n",
    "    print(f\"   Hasil disimpan di: {output_path}\")\n",
    "    \n",
    "    if failed_lines:\n",
    "        print(f\"\\n‚ùå Baris yang gagal (total {len(failed_lines)} baris):\")\n",
    "        for i, (line_num, failed_line) in enumerate(failed_lines[:5]):\n",
    "            print(f\"   Baris {line_num}: {failed_line[:100]}...\")\n",
    "\n",
    "def validate_csv_format(file_path):\n",
    "    \"\"\"Validasi format CSV hasil pembersihan\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"\\n‚úÖ File berhasil dibaca oleh pandas!\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"   Kolom: {list(df.columns)}\")\n",
    "        print(f\"\\nüìä Sample data (3 baris pertama):\")\n",
    "        print(\"=\" * 100)\n",
    "        for i in range(min(3, len(df))):\n",
    "            print(f\"Baris {i+1}:\")\n",
    "            print(f\"  JUDUL:  {df['judul'].iloc[i]}\")\n",
    "            print(f\"  KONTEN: {df['konten'].iloc[i][:100]}...\")\n",
    "            print(\"-\" * 100)\n",
    "        \n",
    "       \n",
    "        print(f\"\\nüîç Format file sebenarnya:\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i < 4:  \n",
    "                    print(f\"Line {i}: {repr(line.strip())}\")\n",
    "                else:\n",
    "                    break\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR saat membaca file dengan pandas: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_test_file(input_path, output_test_path, num_lines=12):\n",
    "    \n",
    "    print(f\"\\nüîß Membuat file test ({num_lines} baris pertama)...\")\n",
    "    \n",
    "    success_count = 0\n",
    "    \n",
    "    with open(input_path, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "         open(output_test_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        \n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)\n",
    "        writer.writerow(['judul', 'konten'])\n",
    "        \n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            line = line.strip()\n",
    "            \n",
    "            if not line or line.lower().replace('\"', '') in ['judul,konten', 'title,content']:\n",
    "                continue\n",
    "            \n",
    "            if success_count >= num_lines:\n",
    "                break\n",
    "            \n",
    "           \n",
    "            print(f\"\\n--- Baris {line_num} (Original) ---\")\n",
    "            print(f\"Raw: {repr(line)}\")\n",
    "            print(f\"Quote count: {line.count(chr(34))}\") \n",
    "            \n",
    "            \n",
    "            parsed = parse_csv_line_robust(line)\n",
    "            if parsed and len(parsed) == 2:\n",
    "                judul, konten = parsed\n",
    "                judul, konten = ensure_proper_quotes(judul, konten)\n",
    "                \n",
    "                print(f\"Judul (cleaned): {repr(judul)}\")\n",
    "                print(f\"Konten (cleaned): {repr(konten[:50])}...\")\n",
    "                \n",
    "                writer.writerow([judul, konten])\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"‚ùå Gagal parsing baris {line_num}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_filepath = os.path.join('datasets_cleaned', 'tempo.csv')\n",
    "    output_test_path = os.path.join('cleaned', 'tempo_cleaned.csv')\n",
    "    \n",
    "    if not os.path.exists(input_filepath):\n",
    "        print(f\"‚ùå File input tidak ditemukan: {input_filepath}\")\n",
    "        print(\"   Pastikan file datasets_cleaned/tempo.csv ada\")\n",
    "    else:\n",
    "        create_test_file(input_filepath, output_test_path, 10000)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VALIDASI FILE TEST:\")\n",
    "        print(\"=\"*80)\n",
    "        validate_csv_format(output_test_path)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VALIDASI FILE LENGKAP:\")\n",
    "        print(\"=\"*80)\n",
    "        validate_csv_format(output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd06767",
   "metadata": {},
   "source": [
    "`Ugm Dataset` - `fix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25237ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_excessive_quotes(text):\n",
    "    if not text:\n",
    "        return text\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    if text.count('\"') >= 4:\n",
    "        print(f\"DEBUG: Banyak kutip ditemukan: {text[:100]}...\")\n",
    "    \n",
    "    while text.startswith('\"\"\"'):\n",
    "        text = text[3:]\n",
    "    while text.startswith('\"\"'):\n",
    "        text = text[2:]\n",
    "    if text.startswith('\"'):\n",
    "        text = text[1:]\n",
    "    \n",
    "    while text.endswith('\"\"\"'):\n",
    "        text = text[:-3]\n",
    "    while text.endswith('\"\"'):\n",
    "        text = text[:-2]\n",
    "    if text.endswith('\"'):\n",
    "        text = text[:-1]\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def remove_source_prefix(text):\n",
    "    if not text:\n",
    "        return text\n",
    "    \n",
    "    patterns = [\n",
    "        r'^\"\\s*KOMPAS\\.com\\s*[‚Äì\\-]\\s*',\n",
    "        r'^KOMPAS\\.com\\s*[‚Äì\\-]\\s*',\n",
    "        r'^\"\\s*KOMPAS\\.com\\s*',\n",
    "        r'^KOMPAS\\.com\\s*',\n",
    "        r'^\\(\\s*KOMPAS\\.com\\s*\\)\\s*',\n",
    "        r'^\\[\\s*KOMPAS\\.com\\s*\\]\\s*'\n",
    "    ]\n",
    "    \n",
    "    cleaned_text = text.strip()\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.match(pattern, cleaned_text, re.IGNORECASE):\n",
    "            cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.IGNORECASE)\n",
    "            break\n",
    "    \n",
    "   \n",
    "    cleaned_text = cleaned_text.replace('\"\"', '\"')\n",
    "    \n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def parse_csv_line_robust(line):\n",
    "   \n",
    "    line = line.strip()\n",
    "    \n",
    "   \n",
    "    try:\n",
    "        reader = csv.reader([line], quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "        row = next(reader)\n",
    "        if len(row) == 2:\n",
    "            return [clean_excessive_quotes(row[0]), clean_excessive_quotes(row[1])]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "   \n",
    "    match = re.match(r'^\"([^\"]*)\"\\s*,\\s*\"([^\"]*)\"$', line)\n",
    "    if match:\n",
    "        judul = clean_excessive_quotes(match.group(1))\n",
    "        konten = clean_excessive_quotes(match.group(2))\n",
    "        return [judul, konten]\n",
    "    \n",
    "\n",
    "    if line.count('\"') >= 4:\n",
    "       \n",
    "        parts = re.split(r',\\s*\"', line, 1)\n",
    "        if len(parts) == 2:\n",
    "            judul = clean_excessive_quotes(parts[0])\n",
    "            konten = '\"' + parts[1]  \n",
    "            konten = clean_excessive_quotes(konten)\n",
    "            return [judul, konten]\n",
    "    \n",
    "    \n",
    "    if ',' in line:\n",
    "        first_comma = line.find(',')\n",
    "        judul = line[:first_comma].strip()\n",
    "        konten = line[first_comma+1:].strip()\n",
    "        \n",
    "        judul = clean_excessive_quotes(judul)\n",
    "        konten = clean_excessive_quotes(konten)\n",
    "        \n",
    "        return [judul, konten]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def ensure_proper_quotes(judul, konten):\n",
    "   \n",
    "   \n",
    "    judul = clean_excessive_quotes(judul)\n",
    "    konten = clean_excessive_quotes(konten)\n",
    "    \n",
    "   \n",
    "    konten = remove_source_prefix(konten)\n",
    "    \n",
    "   \n",
    "    judul = judul.strip('\"')\n",
    "    konten = konten.strip('\"')\n",
    "    \n",
    "    return judul, konten\n",
    "\n",
    "def clean_and_split_csv(input_path, output_path):\n",
    "    print(f\"-> Memulai pembersihan untuk: {os.path.basename(input_path)}\")\n",
    "\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    failed_lines = []\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    with open(input_path, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "         open(output_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "\n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)  \n",
    "        writer.writerow(['judul', 'konten'])\n",
    "\n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            line = line.strip()\n",
    "            \n",
    "            if not line or line.lower().replace('\"', '') in ['judul,konten', 'title,content']:\n",
    "                continue\n",
    "            \n",
    "           \n",
    "            if line.count('\"') > 4:\n",
    "                print(f\"DEBUG Line {line_num}: {line[:100]}...\")\n",
    "\n",
    "           \n",
    "            parsed = parse_csv_line_robust(line)\n",
    "            if parsed and len(parsed) == 2:\n",
    "                judul, konten = parsed\n",
    "                judul, konten = ensure_proper_quotes(judul, konten)\n",
    "                \n",
    "                writer.writerow([judul, konten])\n",
    "                success_count += 1\n",
    "                continue\n",
    "\n",
    "            \n",
    "            fail_count += 1\n",
    "            failed_lines.append((line_num, line))\n",
    "\n",
    "    print(f\"-> ‚úÖ Selesai. Berhasil: {success_count} baris, Gagal: {fail_count} baris.\")\n",
    "    print(f\"   Hasil disimpan di: {output_path}\")\n",
    "    \n",
    "    if failed_lines:\n",
    "        print(f\"\\n‚ùå Baris yang gagal (total {len(failed_lines)} baris):\")\n",
    "        for i, (line_num, failed_line) in enumerate(failed_lines[:5]):\n",
    "            print(f\"   Baris {line_num}: {failed_line[:100]}...\")\n",
    "\n",
    "def validate_csv_format(file_path):\n",
    "    \"\"\"Validasi format CSV hasil pembersihan\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"\\n‚úÖ File berhasil dibaca oleh pandas!\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"   Kolom: {list(df.columns)}\")\n",
    "        print(f\"\\nüìä Sample data (3 baris pertama):\")\n",
    "        print(\"=\" * 100)\n",
    "        for i in range(min(3, len(df))):\n",
    "            print(f\"Baris {i+1}:\")\n",
    "            print(f\"  JUDUL:  {df['judul'].iloc[i]}\")\n",
    "            print(f\"  KONTEN: {df['konten'].iloc[i][:100]}...\")\n",
    "            print(\"-\" * 100)\n",
    "        \n",
    "        \n",
    "        print(f\"\\nüîç Format file sebenarnya:\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i < 4:  \n",
    "                    print(f\"Line {i}: {repr(line.strip())}\")\n",
    "                else:\n",
    "                    break\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR saat membaca file dengan pandas: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_test_file(input_path, output_test_path, num_lines=12):\n",
    "    print(f\"\\nüîß Membuat file test ({num_lines} baris pertama)...\")\n",
    "    \n",
    "    success_count = 0\n",
    "    \n",
    "    with open(input_path, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "         open(output_test_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        \n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)\n",
    "        writer.writerow(['judul', 'konten'])\n",
    "        \n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            line = line.strip()\n",
    "            \n",
    "            if not line or line.lower().replace('\"', '') in ['judul,konten', 'title,content']:\n",
    "                continue\n",
    "            \n",
    "            if success_count >= num_lines:\n",
    "                break\n",
    "            \n",
    "        \n",
    "            print(f\"\\n--- Baris {line_num} (Original) ---\")\n",
    "            print(f\"Raw: {repr(line)}\")\n",
    "            print(f\"Quote count: {line.count(chr(34))}\") \n",
    "            \n",
    "           \n",
    "            parsed = parse_csv_line_robust(line)\n",
    "            if parsed and len(parsed) == 2:\n",
    "                judul, konten = parsed\n",
    "                judul, konten = ensure_proper_quotes(judul, konten)\n",
    "                \n",
    "                print(f\"Judul (cleaned): {repr(judul)}\")\n",
    "                print(f\"Konten (cleaned): {repr(konten[:50])}...\")\n",
    "                \n",
    "                writer.writerow([judul, konten])\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"‚ùå Gagal parsing baris {line_num}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_filepath = os.path.join('datasets_cleaned', 'etd_ugm.csv')\n",
    "    output_test_path = os.path.join('cleaned', 'etd_ugm_cleaned.csv')\n",
    "    \n",
    "    if not os.path.exists(input_filepath):\n",
    "        print(f\"‚ùå File input tidak ditemukan: {input_filepath}\")\n",
    "        print(\"   Pastikan file datasets_cleaned/etd_ugm.csv ada\")\n",
    "    else:\n",
    "        create_test_file(input_filepath, output_test_path, 50000)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VALIDASI FILE TEST:\")\n",
    "        print(\"=\"*80)\n",
    "        validate_csv_format(output_test_path)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VALIDASI FILE LENGKAP:\")\n",
    "        print(\"=\"*80)\n",
    "        validate_csv_format(output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3f7eb6",
   "metadata": {},
   "source": [
    "`Dataset etd_usk` - `Fix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_excessive_quotes(text):\n",
    "    \n",
    "    if not text:\n",
    "        return text\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    if text.count('\"') >= 4:\n",
    "        print(f\"DEBUG: Banyak kutip ditemukan: {text[:100]}...\")\n",
    "    \n",
    "   \n",
    "    while text.startswith('\"\"\"'):\n",
    "        text = text[3:]\n",
    "    while text.startswith('\"\"'):\n",
    "        text = text[2:]\n",
    "    if text.startswith('\"'):\n",
    "        text = text[1:]\n",
    "    \n",
    "    \n",
    "    while text.endswith('\"\"\"'):\n",
    "        text = text[:-3]\n",
    "    while text.endswith('\"\"'):\n",
    "        text = text[:-2]\n",
    "    if text.endswith('\"'):\n",
    "        text = text[:-1]\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def remove_source_prefix(text):\n",
    "   \n",
    "    if not text:\n",
    "        return text\n",
    "    \n",
    "   \n",
    "    patterns = [\n",
    "        r'^\"\\s*KOMPAS\\.com\\s*[‚Äì\\-]\\s*',\n",
    "        r'^KOMPAS\\.com\\s*[‚Äì\\-]\\s*',\n",
    "        r'^\"\\s*KOMPAS\\.com\\s*',\n",
    "        r'^KOMPAS\\.com\\s*',\n",
    "        r'^\\(\\s*KOMPAS\\.com\\s*\\)\\s*',\n",
    "        r'^\\[\\s*KOMPAS\\.com\\s*\\]\\s*'\n",
    "    ]\n",
    "    \n",
    "    cleaned_text = text.strip()\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.match(pattern, cleaned_text, re.IGNORECASE):\n",
    "            cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.IGNORECASE)\n",
    "            break\n",
    "    \n",
    "    \n",
    "    cleaned_text = cleaned_text.replace('\"\"', '\"')\n",
    "    \n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def parse_csv_line_robust(line):\n",
    "  \n",
    "    line = line.strip()\n",
    "    \n",
    "   \n",
    "    try:\n",
    "        reader = csv.reader([line], quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "        row = next(reader)\n",
    "        if len(row) == 2:\n",
    "            return [clean_excessive_quotes(row[0]), clean_excessive_quotes(row[1])]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    match = re.match(r'^\"([^\"]*)\"\\s*,\\s*\"([^\"]*)\"$', line)\n",
    "    if match:\n",
    "        judul = clean_excessive_quotes(match.group(1))\n",
    "        konten = clean_excessive_quotes(match.group(2))\n",
    "        return [judul, konten]\n",
    "    \n",
    "   \n",
    "    if line.count('\"') >= 4:\n",
    "       \n",
    "        parts = re.split(r',\\s*\"', line, 1)\n",
    "        if len(parts) == 2:\n",
    "            judul = clean_excessive_quotes(parts[0])\n",
    "            konten = '\"' + parts[1]  \n",
    "            konten = clean_excessive_quotes(konten)\n",
    "            return [judul, konten]\n",
    "    \n",
    "    \n",
    "    if ',' in line:\n",
    "        first_comma = line.find(',')\n",
    "        judul = line[:first_comma].strip()\n",
    "        konten = line[first_comma+1:].strip()\n",
    "        \n",
    "        judul = clean_excessive_quotes(judul)\n",
    "        konten = clean_excessive_quotes(konten)\n",
    "        \n",
    "        return [judul, konten]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def ensure_proper_quotes(judul, konten):\n",
    "    \n",
    "    judul = clean_excessive_quotes(judul)\n",
    "    konten = clean_excessive_quotes(konten)\n",
    "    \n",
    "   \n",
    "    konten = remove_source_prefix(konten)\n",
    "    \n",
    "   \n",
    "    judul = judul.strip('\"')\n",
    "    konten = konten.strip('\"')\n",
    "    \n",
    "    return judul, konten\n",
    "\n",
    "def clean_and_split_csv(input_path, output_path):\n",
    "    print(f\"-> Memulai pembersihan untuk: {os.path.basename(input_path)}\")\n",
    "\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    failed_lines = []\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    with open(input_path, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "         open(output_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "\n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)  \n",
    "        writer.writerow(['judul', 'konten'])\n",
    "\n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            line = line.strip()\n",
    "            \n",
    "          \n",
    "            if not line or line.lower().replace('\"', '') in ['judul,konten', 'title,content']:\n",
    "                continue\n",
    "            \n",
    "           \n",
    "            if line.count('\"') > 4:\n",
    "                print(f\"DEBUG Line {line_num}: {line[:100]}...\")\n",
    "\n",
    "           \n",
    "            parsed = parse_csv_line_robust(line)\n",
    "            if parsed and len(parsed) == 2:\n",
    "                judul, konten = parsed\n",
    "                judul, konten = ensure_proper_quotes(judul, konten)\n",
    "                \n",
    "                writer.writerow([judul, konten])\n",
    "                success_count += 1\n",
    "                continue\n",
    "\n",
    "            \n",
    "            fail_count += 1\n",
    "            failed_lines.append((line_num, line))\n",
    "\n",
    "    print(f\"-> ‚úÖ Selesai. Berhasil: {success_count} baris, Gagal: {fail_count} baris.\")\n",
    "    print(f\"   Hasil disimpan di: {output_path}\")\n",
    "    \n",
    "    if failed_lines:\n",
    "        print(f\"\\n‚ùå Baris yang gagal (total {len(failed_lines)} baris):\")\n",
    "        for i, (line_num, failed_line) in enumerate(failed_lines[:5]):\n",
    "            print(f\"   Baris {line_num}: {failed_line[:100]}...\")\n",
    "\n",
    "def validate_csv_format(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"\\n‚úÖ File berhasil dibaca oleh pandas!\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"   Kolom: {list(df.columns)}\")\n",
    "        print(f\"\\nüìä Sample data (3 baris pertama):\")\n",
    "        print(\"=\" * 100)\n",
    "        for i in range(min(3, len(df))):\n",
    "            print(f\"Baris {i+1}:\")\n",
    "            print(f\"  JUDUL:  {df['judul'].iloc[i]}\")\n",
    "            print(f\"  KONTEN: {df['konten'].iloc[i][:100]}...\")\n",
    "            print(\"-\" * 100)\n",
    "        \n",
    "       \n",
    "        print(f\"\\nüîç Format file sebenarnya:\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i < 4: \n",
    "                    print(f\"Line {i}: {repr(line.strip())}\")\n",
    "                else:\n",
    "                    break\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR saat membaca file dengan pandas: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_test_file(input_path, output_test_path, num_lines=12):\n",
    "    \n",
    "    print(f\"\\nüîß Membuat file test ({num_lines} baris pertama)...\")\n",
    "    \n",
    "    success_count = 0\n",
    "    \n",
    "    with open(input_path, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "         open(output_test_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        \n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)\n",
    "        writer.writerow(['judul', 'konten'])\n",
    "        \n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            line = line.strip()\n",
    "            \n",
    "            if not line or line.lower().replace('\"', '') in ['judul,konten', 'title,content']:\n",
    "                continue\n",
    "            \n",
    "            if success_count >= num_lines:\n",
    "                break\n",
    "            \n",
    "           \n",
    "            print(f\"\\n--- Baris {line_num} (Original) ---\")\n",
    "            print(f\"Raw: {repr(line)}\")\n",
    "            print(f\"Quote count: {line.count(chr(34))}\")  \n",
    "            \n",
    "           \n",
    "            parsed = parse_csv_line_robust(line)\n",
    "            if parsed and len(parsed) == 2:\n",
    "                judul, konten = parsed\n",
    "                judul, konten = ensure_proper_quotes(judul, konten)\n",
    "                \n",
    "                print(f\"Judul (cleaned): {repr(judul)}\")\n",
    "                print(f\"Konten (cleaned): {repr(konten[:50])}...\")\n",
    "                \n",
    "                writer.writerow([judul, konten])\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"‚ùå Gagal parsing baris {line_num}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_filepath = os.path.join('datasets_cleaned', 'etd_usk.csv')\n",
    "    output_test_path = os.path.join('cleaned', 'etd_usk_cleaned.csv')\n",
    "    \n",
    "    if not os.path.exists(input_filepath):\n",
    "        print(f\"‚ùå File input tidak ditemukan: {input_filepath}\")\n",
    "        print(\"   Pastikan file datasets_cleaned/tempo.csv ada\")\n",
    "    else:\n",
    "        create_test_file(input_filepath, output_test_path, 10000)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VALIDASI FILE TEST:\")\n",
    "        print(\"=\"*80)\n",
    "        validate_csv_format(output_test_path)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VALIDASI FILE LENGKAP:\")\n",
    "        print(\"=\"*80)\n",
    "        validate_csv_format(output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47f67c3-c064-4aa3-b3f3-9828f157370e",
   "metadata": {},
   "source": [
    "## Merge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4276ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konfigurasi selesai:\n",
      "Input direktori: cleaned\n",
      "Output direktori: merge_datasets\n",
      "File output: merge_datasets\\0_mergeDataset.csv\n",
      "============================================================\n",
      "üîπ Membaca etd_ugm_cleaned.csv ...\n",
      "üîπ Membaca etd_usk_cleaned.csv ...\n",
      "üîπ Membaca kompas_cleaned.csv ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Membaca mojok_cleaned.csv ...\n",
      "üîπ Membaca tempo_cleaned.csv ...\n",
      "============================================================\n",
      "‚úÖ Total data gabungan: 46531 baris, 2 kolom\n",
      "üíæ Hasil gabungan disimpan di: merge_datasets\\0_mergeDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Direktori tempat dataset asli Anda berada\n",
    "input_dir = 'cleaned'\n",
    "\n",
    "# Direktori untuk menyimpan hasil gabungan\n",
    "output_dir = 'merge_datasets'\n",
    "\n",
    "# Daftar nama file yang akan digabungkan\n",
    "files_to_merge = [\n",
    "    'etd_ugm_cleaned.csv', \n",
    "    'etd_usk_cleaned.csv', \n",
    "    'kompas_cleaned.csv', \n",
    "    'mojok_cleaned.csv', \n",
    "    'tempo_cleaned.csv'\n",
    "]\n",
    "\n",
    "# Nama file akhir setelah semua dataset digabungkan\n",
    "output_filename = os.path.join(output_dir, '0_mergeDataset.csv')\n",
    "\n",
    "# Ukuran chunk (kalau file besar banget)\n",
    "chunk_size = 10000\n",
    "\n",
    "print(\"Konfigurasi selesai:\")\n",
    "print(f\"Input direktori: {input_dir}\")\n",
    "print(f\"Output direktori: {output_dir}\")\n",
    "print(f\"File output: {output_filename}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Pastikan direktori output ada\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Proses penggabungan\n",
    "for file_name in files_to_merge:\n",
    "    file_path = os.path.join(input_dir, file_name)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ùå File tidak ditemukan: {file_name}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"üîπ Membaca {file_name} ...\")\n",
    "    \n",
    "    try:\n",
    "        chunks = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "        for chunk in chunks:\n",
    "            merged_df = pd.concat([merged_df, chunk], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Gagal membaca {file_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ Total data gabungan: {merged_df.shape[0]} baris, {merged_df.shape[1]} kolom\")\n",
    "\n",
    "merged_df.to_csv(output_filename, index=False, quoting=1, encoding='utf-8')\n",
    "\n",
    "print(f\"üíæ Hasil gabungan disimpan di: {output_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
